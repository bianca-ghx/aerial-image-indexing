{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":668380,"sourceType":"datasetVersion","datasetId":336091},{"sourceId":2271054,"sourceType":"datasetVersion","datasetId":76785},{"sourceId":5049427,"sourceType":"datasetVersion","datasetId":2931535}],"dockerImageVersionId":30152,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import glob\nfrom collections import Counter\nfrom itertools import chain\nimport os\nimport re\nimport random\nimport zipfile\nimport shutil\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models\nfrom torchsummary import summary\n\nimport faiss  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Dataset","metadata":{}},{"cell_type":"code","source":"test_size = 0.15\nval_size = 0.15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/ucmerced-landuse/UCMerced_LandUse/Images'\ntrain_dir = 'train'\nval_dir = 'val'\ntest_dir = 'test'\n\n# Create directories to store train, validation and test data \nif not os.path.exists(train_dir):\n    os.makedirs(train_dir)\nif not os.path.exists(val_dir):\n    os.makedirs(val_dir)\nif not os.path.exists(test_dir):\n    os.makedirs(test_dir)\n    \nclasses = os.listdir(data_dir)\n\n# Iterate through each class \nfor clss in classes:\n    # Define class path\n    clss_path = os.path.join(data_dir, clss)\n    # Get paths to all images in class path\n    images = os.listdir(clss_path)\n    \n    # Split into train, validation and test\n    train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)\n    train_images, val_images = train_test_split(train_images, test_size=val_size/(1-test_size), random_state=42)\n    \n    # Copy train images to train directory\n    for train_image in train_images:\n        src = os.path.join(clss_path, train_image)\n        dst = os.path.join(train_dir, clss)\n        if not os.path.exists(dst):\n            os.makedirs(dst)\n        shutil.copy(src, os.path.join(dst, train_image))\n    \n    # Copy validation images to validation directory\n    for val_image in val_images:\n        src = os.path.join(clss_path, val_image)\n        dst = os.path.join(val_dir, clss)\n        if not os.path.exists(dst):\n            os.makedirs(dst)\n        shutil.copy(src, os.path.join(dst, val_image))\n    \n    # Copy test images to test directory\n    for test_image in test_images:\n        src = os.path.join(clss_path, test_image)\n        dst = os.path.join(test_dir, clss)\n        if not os.path.exists(dst):\n            os.makedirs(dst)\n        shutil.copy(src, os.path.join(dst, test_image))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Dataloader","metadata":{}},{"cell_type":"code","source":"PATH_TRAIN = \"/kaggle/working/train\"\nPATH_VALID = \"/kaggle/working/val\"\nPATH_TEST = \"/kaggle/working/test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TripletData(Dataset):\n    def __init__(self, path, transforms, split=\"train\"):\n        self.path = path # path of data folder\n        self.split = split    # train or valid\n        self.transforms = transforms # data transformations\n        self.class_folders = os.listdir(path)  # list of class folder names\n\n    def __getitem__(self, idx):\n        # Select a positive class\n        positive_class = self.class_folders[idx % len(self.class_folders)]\n        # Choose a pair of positive images (im1, im2)\n        positives = os.listdir(os.path.join(self.path, positive_class))\n        im1, im2 = random.sample(positives, 2)\n        # Choose a negative class and an image from it (im3)\n        negative_class = random.choice([c for c in self.class_folders if c != positive_class])\n        negatives = os.listdir(os.path.join(self.path, negative_class))\n        im3 = random.choice(negatives)\n        \n        # Construct full image paths\n        im1_path = os.path.join(self.path, positive_class, im1)\n        im2_path = os.path.join(self.path, positive_class, im2)\n        im3_path = os.path.join(self.path, negative_class, im3)\n\n        # Apply transforms and open images\n        im1 = self.transforms(Image.open(im1_path))\n        im2 = self.transforms(Image.open(im2_path))\n        im3 = self.transforms(Image.open(im3_path))\n\n        return [im1, im2, im3]\n\n    def __len__(self):\n        return len(self.class_folders) * 8\n\n# Transforms\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Datasets and Dataloaders\ntrain_data = TripletData(PATH_TRAIN, train_transforms)\nval_data = TripletData(PATH_VALID, val_transforms)\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=32, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=32, shuffle=False, num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Loss Function","metadata":{}},{"cell_type":"code","source":"class TripletLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        \n    def calc_euclidean(self, x1, x2):\n        return (x1 - x2).pow(2).sum(1)\n    \n    # Distances in embedding space is calculated in euclidean\n    def forward(self, anchor, positive, negative):\n        distance_positive = self.calc_euclidean(anchor, positive)\n        distance_negative = self.calc_euclidean(anchor, negative)\n        losses = torch.relu(distance_positive - distance_negative + self.margin)\n        return losses.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract Image Features w/ ResNet","metadata":{}},{"cell_type":"code","source":"# Define no. epochs and device\nepochs = 15\ndevice = 'cuda'\n\n# Base model\nmodel = models.resnet34().cuda()\n# Change last FC layer to identity layer\nmodel.fc = torch.nn.Identity()\n\n# For double GPU usage\nmodel = nn.DataParallel(model)\nmodel.to(device)\n\n# ADAM optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ntriplet_loss = TripletLoss()\n\nfor epoch in range(epochs):\n    # Training\n    model.train() # Set the model in training mode\n    epoch_loss = 0.0 # Initialize the loss as 0\n    for data in tqdm(train_loader):\n        optimizer.zero_grad() # Set gradients to 0 for current mini-batch\n        x1,x2,x3 = data # Get data and send to GPU\n        e1 = model(x1.to(device))\n        e2 = model(x2.to(device))\n        e3 = model(x3.to(device)) \n        \n        loss = triplet_loss(e1,e2,e3) # Compute triplet loss\n        epoch_loss += loss # Add current loss to overall epoch_loss\n        loss.backward() # Backpropagate\n        optimizer.step() # Update weights\n    print(\"Train Loss: {}\".format(epoch_loss.item())) # Print epoch loss\n    \n    # Validation\n    model.eval() # Put model in evaluation mode\n    val_loss = 0.0 # Initialize the loss to 0\n    with torch.no_grad():\n        for data in val_loader:\n            x1, x2, x3 = data # Get images and send to GPU\n            e1 = model(x1.to(device))\n            e2 = model(x2.to(device))\n            e3 = model(x3.to(device))\n\n            loss = triplet_loss(e1, e2, e3) # Compute triplet loss\n            val_loss += loss.item() # Add current loss to overall validation loss\n    print(\"Validation Loss: {:.4f}\".format(val_loss)) # Print validation loss","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model, (3, 224, 224))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Index Images","metadata":{}},{"cell_type":"code","source":"faiss_index = faiss.IndexFlatL2(512)   # build the index\n\nim_indices = []\nwith torch.no_grad(): # Set such that no gradients are computed \n    for f in tqdm(glob.glob(os.path.join(PATH_TRAIN, '*/*'))): # For each image in training dataset\n        im = Image.open(f) # Open image\n        im = im.resize((224,224)) # Resize\n        im = torch.tensor([val_transforms(im).numpy()]).cuda() # Add transforms, convert to np, then to tensor and send to GPU\n    \n        preds = model(im) # Get image prediction\n        preds = np.array([preds[0].cpu().numpy()]) # Send back to cpu and convert to numpy array\n        faiss_index.add(preds) # Add the representation to index\n        im_indices.append(f)   # Store the image name to find it later on","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Retrieve Images","metadata":{}},{"cell_type":"code","source":"with torch.no_grad(): # Set such that no gradients are computed \n    for class_folder in os.listdir(PATH_TEST): # For each class in test dataset\n        class_folder_path = os.path.join(PATH_TEST, class_folder) # Define class folder path\n        for f in os.listdir(class_folder_path): # For each image in test dataset\n            file_path = os.path.join(class_folder_path, f) # Get image path\n            im = Image.open(file_path) # Open image\n            im = im.resize((224,224)) # Resize\n            im = torch.tensor([val_transforms(im).numpy()]).cuda() # Add transforms, convert to np, then to tensor and send to GPU\n        \n            test_embed = model(im).cpu().numpy() # Get image prediction, send back to cpu and convert to numpy array\n            _, I = faiss_index.search(test_embed, 5) # Get the most similar images\n            print(\"Retrieved Image: {}\".format(im_indices[I[0][0]]))  ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Examples","metadata":{}},{"cell_type":"code","source":"# Function to retrieve similar images\ndef process_image(image_path, target_size=(224,224)):\n    im = Image.open(image_path)\n    im = im.resize((224,224))\n    im = torch.tensor([val_transforms(im).numpy()]).cuda()\n    \n    return im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_similar_images(img_path, model, faiss_index, im_indices, num_similar=5):\n\n    im = process_image(img_path)\n\n    test_embed = model(im).cpu().detach().numpy()\n    \n    distances, I = faiss_index.search(test_embed, num_similar)\n    similar_images_paths = [im_indices[i] for i in I[0]]\n    \n    return similar_images_paths, I, distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select 10 random test images from different subdirectories\ntest_image_paths = []\nfor class_folder in random.sample(os.listdir(PATH_TEST), 10):\n    class_folder_path = os.path.join(PATH_TEST, class_folder)\n    image_file = random.choice(os.listdir(class_folder_path))\n    test_image_paths.append(os.path.join(class_folder_path, image_file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Example 1: IndexFlatL2","metadata":{}},{"cell_type":"code","source":"# Plotting\nfig, axs = plt.subplots(10, 6, figsize=(15, 15))\nfor row, test_image_path in enumerate(test_image_paths):\n    similar_images, I, _ = get_similar_images(test_image_path, model, faiss_index, im_indices)             \n    # Extracting class name from path                        \n    class_name = os.path.basename(os.path.dirname(test_image_path))  \n    \n    # Plot setup                         \n    axs[row, 0].imshow(Image.open(test_image_path))\n    axs[row, 0].set_title(f\"Test: {class_name}\")\n    axs[row, 0].axis('off')\n    \n    for col, similar_image_path in enumerate(similar_images, 1):\n        similar_class_name = os.path.basename(os.path.dirname(similar_image_path))  # Class of similar image\n        axs[row, col].imshow(Image.open(similar_image_path))\n        axs[row, col].set_title(f\"Similar {col} ({similar_class_name})\")\n        axs[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/figures","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_faiss_distances(distances):\n    \"\"\"\n    Plots the evolution of distances from a FAISS search.\n    \n    :param distances: A 2D numpy array where each row contains the distances \n                      of the nearest neighbors for a particular query.\n    \"\"\"\n    if distances.ndim == 1:\n        # If there's only one query, reshape the array for compatibility\n        distances = distances.reshape(1, -1)\n    \n    num_queries = distances.shape[0]\n    \n    plt.figure(figsize=(12, 8))\n    \n    for i in range(num_queries):\n        plt.plot(distances[i])\n    \n    plt.title('Evolution of FAISS Distances')\n    plt.xlabel('Rank of Neighbors')\n    plt.ylabel('Distance')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(\"/kaggle/working/figures/Distances.png\")\n    \n    plt.show()\n    \nfor row, test_image_path in enumerate(test_image_paths):\n    similar_images, I, distances = get_similar_images(test_image_path, model, faiss_index, im_indices, 50)\n    \nprint(\"Check if distance are sorted:\", np.all(distances[:-1] <= distances[1:]))\n\nplot_faiss_distances(distances)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_histograms(data_dicts, title_list, multiplier):\n    \"\"\"\n    Plots up to 3 histograms in a single figure from a list of dictionaries.\n\n    :param data_dicts: List of dictionaries, each with class names as keys and numeric values.\n    \"\"\"\n    \n    # Create a new figure\n    plt.figure(figsize=(12, 4))\n\n    for i, data_dict in enumerate(data_dicts, start=1):\n        # Creating a subplot for each histogram\n        plt.subplot(1, 3, i)\n        \n        # Extracting class names and their corresponding values\n        class_names = list(data_dict.keys())\n        values = list(data_dict.values())\n\n        # Creating the histogram in the subplot\n        plt.bar(class_names, values)\n        plt.xticks(rotation=90)  # Rotate the x-axis labels vertically\n        # Adding subplot title\n        plt.title(f'Retrieved Images for class \"{title_list[i+multiplier-1]}\"')\n\n    # Adjust the layout so that labels don't overlap\n    plt.tight_layout()\n\n    # Display the plot\n    plt.show()\n    \ndef split_filename(filename):\n    \"\"\"\n    Splits a filename into a non-digit part and a digit part.\n\n    :param filename: The filename string.\n    :return: A tuple of (non-digit part, digit part).\n    \"\"\"\n    filename = filename.split('/')[-1].split('__')[-1].split(\".\")[0]\n    match = re.search(r'(\\D+)(\\d+)$', filename)\n    if match:\n        return match.group(1)\n    else:\n        return filename\n    \n    dict_list = []\ntitle_list = []\n    \nfor class_test_path in os.listdir(PATH_TEST):\n    title_list.append(class_test_path)\n    classes_counts = {}\n    for image_path in os.listdir(os.path.join(PATH_TEST, class_test_path)):\n        # Iterate through each test photo\n        image_path = os.path.join(PATH_TEST, class_test_path, image_path)\n        \n        # Retrieve similar images for each test image in each class   \n        similar_images,_,_ = get_similar_images(image_path, model, faiss_index, im_indices, 50)\n        \n        # Only keep the class name\n        class_name = split_filename(test_image_path)\n        similar_images = list(map(split_filename, similar_images))\n\n        # Count the classes occurances\n        for class_instance in similar_images:\n            if class_instance in classes_counts:\n                classes_counts[class_instance] += 1\n            else:\n                classes_counts[class_instance] = 1\n    dict_list.append(classes_counts)\n\nfor i in range(0, len(dict_list), 3):\n    # Selecting 3 histograms at a time\n    histogram_data_set = dict_list[i:i+3]\n    # Plotting the set of up to 3 histograms\n    plot_histograms(histogram_data_set, title_list, i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Example","metadata":{}},{"cell_type":"code","source":"PATH_BUCURESTI = \"/kaggle/input/test-bucuresti-uc\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting\nfig, axs = plt.subplots(8, 6, figsize=(15, 15))\nfor row, test_image_path in enumerate(test_image_paths):\n    similar_images, I = get_similar_images(test_image_path, model, faiss_index, im_indices, 5)             \n    # Extracting class name from path                        \n    class_name = test_image_path.split('/')[-1].split('__')[-1]\n    \n    # Plot setup       \n    img = Image.open(test_image_path)\n    img = img.resize((224, 224))\n    axs[row, 0].imshow(img)\n    axs[row, 0].set_title(f\"Test: {class_name}\")\n    axs[row, 0].axis('off')\n\n    for col, similar_image_path in enumerate(similar_images, 1):\n        similar_class_name = os.path.basename(os.path.dirname(similar_image_path))  # Class of similar image\n        axs[row, col].imshow(Image.open(similar_image_path))\n        axs[row, col].set_title(f\"Similar {col} ({similar_class_name})\")\n        axs[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}